{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d8177-b40b-4a88-aa39-754eed8ded1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import comet_ml at the top of your file\n",
    "# from comet_ml import Experiment  ### special library to record performance on a web server\n",
    "# from config import * ### file with personal API_KEY\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from skbio.stats.composition import clr\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:1' if use_cuda else 'mps')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b405f9-fa86-4837-b107-8bb326de42c3",
   "metadata": {},
   "source": [
    "### Record experiment on comet.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93515966-5fcc-43a3-ad6b-c1a54ea6d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize comet experiment with your api key\n",
    "'''\n",
    "experiment = Experiment(\n",
    "    api_key=API_KEY,\n",
    "    project_name=\"vae-eco-ml\",\n",
    "    workspace=\"zireae1\",\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ac578-3590-4f2a-917e-57f9787fa629",
   "metadata": {},
   "source": [
    "### Load clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb6011-d277-4972-8f90-e88734dd31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data: rows are samples, columns are species, relative abundance sum ~ [80-100]\n",
    "\n",
    "data_df = pd.read_csv(\"data/wgs_train_health.noab_data_to_ml.filt.txt\", sep=\"\\t\")\n",
    "data_df = data_df.to_numpy()\n",
    "print(data_df.shape)\n",
    "\n",
    "features = np.copy(data_df)\n",
    "labels = np.copy(data_df)\n",
    "\n",
    "#features = np.asarray(features)#/100\n",
    "print(features.shape[0])\n",
    "#labels = np.asarray(labels)#/100\n",
    "print(labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8ced8-2810-45ba-acf8-fc7695e8960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dataset object\n",
    "class CustomDataset(TensorDataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        #self.device=device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]#.to(self.device)\n",
    "        data = self.features[idx]#.to(self.device)\n",
    "        sample = {\"Features\": data, \"Labels\": label}\n",
    "        return sample\n",
    "\n",
    "### prepare train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "### clr transformation for outputs\n",
    "zero_thr = 1e-6\n",
    "gmean_train = (np.exp(np.nansum(np.log(y_train[y_train > 0]+zero_thr)) / np.size(y_train)))\n",
    "y_train_clr = np.log((y_train+zero_thr) / gmean_train)\n",
    "y_test_clr = np.log((y_test+zero_thr)/ gmean_train)\n",
    "\n",
    "y_train_scaled = y_train_clr\n",
    "y_test_scaled = y_test_clr\n",
    "\n",
    "scaler = preprocessing.MaxAbsScaler().fit(y_train_scaled)\n",
    "#scaler = preprocessing.MinMaxScaler().fit(y_train_scaled)\n",
    "y_train_scaled = scaler.transform(y_train_scaled)\n",
    "y_test_scaled = scaler.transform(y_test_scaled)\n",
    "\n",
    "X_train_scaled = y_train_scaled\n",
    "X_test_scaled = y_test_scaled\n",
    "\n",
    "X_train_scaled=torch.from_numpy(X_train_scaled).float()\n",
    "y_train_scaled=torch.from_numpy(y_train_scaled).float()\n",
    "X_test_scaled=torch.from_numpy(X_test_scaled).float()\n",
    "y_test_scaled=torch.from_numpy(y_test_scaled).float()\n",
    "\n",
    "#### dataset build \n",
    "Train = CustomDataset(X_train_scaled, y_train_scaled)\n",
    "Test = CustomDataset(X_test_scaled, y_test_scaled)\n",
    "\n",
    "### create batch spits of data\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "train_DS = DataLoader(Train, batch_size=100, shuffle=True, drop_last=True, **kwargs)\n",
    "test_DS = DataLoader(Test, batch_size=100, shuffle=True, drop_last=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d72941-d9e2-4e86-b446-8be23314f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check distribution of the data\n",
    "plt.hist(X_test_scaled.flatten(), bins=40)\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "#plt.savefig('wgs_filt.pdf', dpi=1000) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d864f4-68e4-4734-aaf6-743f39d0870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate mean for training to compute residual loss:\n",
    "train_means=np.mean(y_train_scaled.numpy(), axis=0)\n",
    "#print(np.mean(train_means))\n",
    "### more sophisticated way means (only for non-zero species)[need to modify]\n",
    "#train_means=(torch.sum(X_train_scaled*y_train_scaled, axis=0)/torch.sum(X_train_scaled, axis=0)).numpy()\n",
    "train_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498ec3e-2013-4920-b05d-475a2563b5e9",
   "metadata": {},
   "source": [
    "### Implement VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58076252-17a8-46ec-8e34-9ad160d89c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "#relu = torch.nn.ELU()\n",
    "input_dim=y_train.shape[1]\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 1024)\n",
    "        #self.fc2 = torch.nn.Linear(90, 80)\n",
    "        self.fc3a = torch.nn.Linear(1024, 64)\n",
    "        self.fc3b = torch.nn.Linear(1024, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 1024)\n",
    "        #self.fc5 = torch.nn.Linear(26, 52)\n",
    "        self.fc6 = torch.nn.Linear(1024, input_dim)\n",
    "        \n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def encode(self, x):  \n",
    "        z = self.fc1(x)\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        #z = torch.tanh(z)\n",
    "        z = relu(z)\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        #z = self.fc2(z)\n",
    "        #z = self.dropout(z)\n",
    "        \n",
    "        #z = torch.tanh(z)\n",
    "        #z = relu(z)\n",
    "        #z = self.dropout(z)\n",
    "        \n",
    "        z1 = self.fc3a(z)  # u \n",
    "        z2 = self.fc3b(z)  # logvar\n",
    "\n",
    "        return (z1, z2)\n",
    "\n",
    "    def decode(self, z):  \n",
    "        z = self.fc4(z)\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        #z = torch.tanh(z)\n",
    "        z = relu(z)\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        #z = self.fc5(z)\n",
    "        #z = self.dropout(z)\n",
    "        \n",
    "        #z = torch.tanh(z)\n",
    "        #z = relu(z)\n",
    "        #z = self.dropout(z)\n",
    "        \n",
    "        z = self.fc6(z)\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        #z = torch.sigmoid(z) ### turn off for abundance prediction\n",
    "        z = torch.tanh(z)\n",
    "        #z = relu(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):  # 784-400-[20,20]-20-400-784\n",
    "        x = x.view(-1, input_dim)\n",
    "        (u, logvar) = self.encode(x)\n",
    "        stdev = torch.exp(0.5 * logvar)\n",
    "        noise = torch.randn_like(stdev)\n",
    "        z = u + 1 * (noise * stdev)  # no noise variation!!!\n",
    "        z = self.decode(z)     # 20-400-784\n",
    "        return (z, u, logvar)\n",
    "\n",
    "### try to penalize many non-zero labels as in L1 lasso?\n",
    "def final_loss(mse_loss, bce_loss, spr_loss, u, logvar, recon_x):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss and the \n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param mse_loss: mse recontruction loss\n",
    "    :param bce_loss: bce recontruction loss\n",
    "    :param spr_loss: custom term in recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    MSE = mse_loss\n",
    "    SPR = spr_loss\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - u.pow(2) - logvar.exp())\n",
    "    \n",
    "    return 0.01 * KLD + MSE + 10 * SPR + 1 * BCE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0d5da-adfb-4af2-b4bd-a22dbca0e15a",
   "metadata": {},
   "source": [
    "### Model Initialization and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ea159-f3e9-40f0-983d-7a92300d142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()#.to(device)\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "criterion_mse = torch.nn.MSELoss(reduction='sum')\n",
    "criterion_bce = torch.nn.BCELoss(reduction='sum')\n",
    "#criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "#criterion_l1 = torch.nn.L1Loss()\n",
    "#criterion_kl_loss = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)\n",
    "\n",
    "# Define L2 regularization strength for weights\n",
    "l2_lambda = 0.01\n",
    "\n",
    "# Using an Adam Optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-7)\n",
    "### iterate through batches\n",
    "epochs = 1000\n",
    "zero_thr = -0.6\n",
    "outputs = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_corr = []\n",
    "test_corr = []\n",
    "train_grad = []\n",
    "epochs_without_improvement=0\n",
    "patience=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #print('Epoch number: ', epoch)\n",
    "    model = model.train()\n",
    "    train_loss = 0.0        # accumulated custom loss\n",
    "    test_loss = 0.0        # accumulated custom loss\n",
    "    corr=0.0\n",
    "    grad_mag=0.0\n",
    "    accs=0.0\n",
    "    \n",
    "    ### VAE training\n",
    "    for (idx, batch) in enumerate(train_DS):\n",
    "\n",
    "        # Transfer to GPU\n",
    "        #batch['Features'], batch['Labels'] = batch['Features'].to(device), batch['Labels'].to(device)\n",
    "\n",
    "        # Output of VAE\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, u, logvar = model(batch['Features'])\n",
    "\n",
    "        ### calculate MSE loss on a data\n",
    "        mse_loss = criterion_mse(recon_x, batch['Labels'])\n",
    "        \n",
    "        spr_loss = criterion_mse(recon_x-torch.from_numpy(train_means)[None,:], batch['Labels']-torch.from_numpy(train_means)[None,:])\n",
    "        out = ((recon_x.detach())>zero_thr).float() ### for MaxAbs scaled\n",
    "        \n",
    "        #bce_loss = criterion_bce(out, batch['Features']) #for binary-abund\n",
    "        bce_loss=0\n",
    "        \n",
    "        # Calculating THE loss function\n",
    "        loss_val = final_loss(mse_loss, bce_loss, spr_loss, u, logvar, recon_x)\n",
    "        \n",
    "        # Compute L2 regularization loss\n",
    "        l2_reg_loss = 0.0\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad:\n",
    "                l2_reg_loss += torch.norm(param, 2)\n",
    "        \n",
    "        # Add L2 regularization loss to the reconstruction loss\n",
    "        total_loss = loss_val + l2_lambda * l2_reg_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        train_loss += loss_val.item()\n",
    "        \n",
    "        true_bin = ((batch['Features'])>zero_thr).float() ### for MaxAbs scaled\n",
    "        acc = (out == true_bin).float().mean()\n",
    "  \n",
    "        acc = float(acc)\n",
    "        accs +=acc\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    # Storing the losses in a list for plotting\n",
    "    train_losses.append(train_loss/len(train_DS))\n",
    "    train_acc.append(accs/len(train_DS))\n",
    "    train_grad.append(grad_mag)\n",
    "\n",
    "    accs=0.0\n",
    "    corr=0.0\n",
    "    \n",
    "    ### VAE evaluation\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        for (idx, batch) in enumerate(test_DS):\n",
    "            # Transfer to GPU\n",
    "            #batch['Features'], batch['Labels'] = batch['Features'].to(device), batch['Labels'].to(device)\n",
    "\n",
    "            recon_x, u, logvar = model(batch['Features'])\n",
    "            # Calculating the loss function\n",
    "            mse_loss = criterion_mse(recon_x, batch['Labels'])\n",
    "    \n",
    "            out = ((recon_x.detach())>zero_thr).float() #for MaxAbs scaled\n",
    "\n",
    "            bce_loss=0\n",
    "\n",
    "            spr_loss = criterion_mse(recon_x-torch.from_numpy(train_means)[None,:], batch['Labels']-torch.from_numpy(train_means)[None,:])\n",
    "            \n",
    "            loss_val = final_loss(mse_loss, bce_loss, spr_loss, u, logvar, recon_x)\n",
    "            test_loss += loss_val.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            true_bin = ((batch['Features'])>zero_thr).float() ### for MaxAbs scaled\n",
    "            acc = (out == true_bin).float().mean() # for binary-abund\n",
    "            acc = float(acc)\n",
    "            accs +=acc\n",
    "\n",
    "        # Storing the losses in a list for plotting\n",
    "        test_losses.append(test_loss/len(test_DS))\n",
    "        test_acc.append(accs/len(test_DS))\n",
    "    \n",
    "    ### Store metrics for comet:\n",
    "    '''\n",
    "    metrics = {'train loss': train_loss/len(train_DS), \n",
    "               'test loss': test_loss/len(test_DS), \n",
    "               'accuracy': accs/len(test_DS),\n",
    "               #'gradient': grad_mag,\n",
    "               #'test_corr': corr/X_test.shape[0]\n",
    "               }\n",
    "    experiment.log_metrics(metrics, step=epoch)\n",
    "    '''\n",
    "    \n",
    "    if train_loss>test_loss:\n",
    "        epochs_without_improvement=0\n",
    "    else:\n",
    "        epochs_without_improvement+=1\n",
    " \n",
    "    if epochs_without_improvement==patience:\n",
    "        print(\"early stop\")\n",
    "        break\n",
    "    #outputs.append((epochs, batch['Features'], reconstructed))\n",
    "# experiment.end() ### end comet experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868252b2-580f-46e8-a90d-efe1ce7bf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check the distribution of reconstructed data:\n",
    "\n",
    "plt.hist(recon_x.detach().numpy().flatten(), bins=40)\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "#plt.savefig('wgs_filt_clr_mse_loss_wide_v2.pdf', dpi=1000) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30de092-56cc-4e42-a59d-8e2321be8eb6",
   "metadata": {},
   "source": [
    "### Look at test set reconstruction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333730d4-0a4f-4c83-86b7-bb7d03479867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check how good the reconstructions are (plot matrices as heatmaps):\n",
    "for (idx, batch) in enumerate(test_DS):\n",
    "    print(idx)\n",
    "    true_x = batch['Labels'].detach().numpy()\n",
    "    #print(true_x)\n",
    "    recon_x, u, logvar = model(batch['Features'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    #fig.suptitle('True vs Reconstructed')\n",
    "    \n",
    "    ax1.imshow(true_x[:,range(input_dim)], cmap='bwr', interpolation='nearest')\n",
    "    ax1.set_title('True')\n",
    "    \n",
    "    a = recon_x.detach().numpy()\n",
    "\n",
    "    ax2.imshow(a[:,range(input_dim)], cmap='bwr', interpolation='nearest')\n",
    "    ax2.set_title('Reconstructed')\n",
    "    \n",
    "    print(stats.spearmanr(true_x.flatten(), a.flatten()))\n",
    "    #plt.savefig('batch_reconstruction_masked_v1_{}_wide.pdf'.format(idx), dpi=1300) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02086f4-bff1-4130-be28-c8129a5df40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check how good the reconstructions are (plot predicted vs observed scatter plot):\n",
    "\n",
    "for (idx, batch) in enumerate(test_DS):\n",
    "    print(idx)\n",
    "    true_x = batch['Labels'].detach().numpy()\n",
    "    #print(true_x)\n",
    "    recon_x, u, logvar = model(batch['Features'])\n",
    "    \n",
    "    a = recon_x.detach().numpy()\n",
    "    #fig.suptitle('True vs Reconstructed')\n",
    "    #plt.scatter(x=true_x, y=a)\n",
    "    plt.hist2d(x=true_x.flatten(), y=a.flatten(), norm=matplotlib.colors.PowerNorm(1/10), bins=100)\n",
    "\n",
    "    #ax1.imshow(true_x[:,range(input_dim)], cmap='bwr', interpolation='nearest')\n",
    "    #ax1.set_title('True')\n",
    "    \n",
    "    \n",
    "\n",
    "    #ax2.imshow(a[:,range(input_dim)], cmap='bwr', interpolation='nearest')\n",
    "    #ax2.set_title('Reconstructed')\n",
    "    \n",
    "    print(stats.spearmanr(true_x.flatten(), a.flatten()))\n",
    "    #plt.savefig('batch_reconstruction_masked_v1_{}_wide.pdf'.format(idx), dpi=1300) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21f6ba-3f61-44fb-a4cd-7ffe0ddc7c5b",
   "metadata": {},
   "source": [
    "### Count true/false positive/negative _per species_ binary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74037a8a-969a-4b57-981f-468a2509fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate true positive:\n",
    "tps=np.zeros((true_x.shape[1], len(test_DS)))\n",
    "tns=np.zeros((true_x.shape[1], len(test_DS)))\n",
    "fps=np.zeros((true_x.shape[1], len(test_DS)))\n",
    "fns=np.zeros((true_x.shape[1], len(test_DS)))\n",
    "prev=np.zeros((true_x.shape[1], len(test_DS)))\n",
    "zero_thr = -0.6\n",
    "accs=0\n",
    "\n",
    "for (idx, batch) in enumerate(test_DS):\n",
    "    print(\"num\")\n",
    "    true_x_bin = (batch['Features']>zero_thr).float()\n",
    "    \n",
    "    recon_x, u, logvar = model(batch['Features'])\n",
    "    recon_x_bin=(recon_x.detach()>zero_thr).float()\n",
    "    \n",
    "    acc = (recon_x_bin == true_x_bin).float().mean()\n",
    "    acc = float(acc)\n",
    "    accs +=acc\n",
    "    \n",
    "    true_x_bin=true_x_bin.numpy()\n",
    "    recon_x_bin=recon_x_bin.numpy()\n",
    "    \n",
    "    print(recon_x_bin.shape)\n",
    "    prev[:,idx]=np.mean(true_x_bin, axis=0)\n",
    "    for i in range(true_x_bin.shape[1]):\n",
    "        tp=0\n",
    "        tn=0\n",
    "        fn=0\n",
    "        fp=0\n",
    "        #print(true_x_bin.shape[0])\n",
    "        for j in range(true_x_bin.shape[0]):\n",
    "            if(true_x_bin[j,i]==1):\n",
    "                if(recon_x_bin[j,i]==1):\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "            else:\n",
    "                if(recon_x_bin[j,i]==1):\n",
    "                    fp+=1\n",
    "                else:\n",
    "                    tn+=1\n",
    "        #print(i)\n",
    "        tps[i, idx]=tp\n",
    "        tns[i, idx]=tn\n",
    "        fps[i, idx]=fp\n",
    "        fns[i, idx]=fn\n",
    "    \n",
    "sum_tps=np.sum(tps, axis=1)\n",
    "sum_tns=np.sum(tns, axis=1)\n",
    "sum_fps=np.sum(fps, axis=1)\n",
    "sum_fns=np.sum(fns, axis=1)\n",
    "sum_prev=np.mean(prev, axis=1)\n",
    "\n",
    "sensitivity=sum_tps/(sum_tps+sum_fns)#+0.5)\n",
    "specificity=sum_tns/(sum_tns+sum_fps)#+0.5)   \n",
    "    \n",
    "print(accs/len(test_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb4bab-db83-4ed5-b4de-fe35c7501deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=sensitivity, y=specificity)\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel(\"Sensitivity\")\n",
    "plt.ylabel(\"Specificity\")\n",
    "plt.legend([\"Spearman r= -0.01\"], frameon=False, loc=3)\n",
    "plt.plot([0.0, 1], [1, 0.0], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "\n",
    "plt.plot([0.2, 1], [1, 0.2], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "plt.plot([0.4, 1], [1, 0.4], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.legend([\"Spearman r=\" + str(np.round(stats.spearmanr(sensitivity, specificity)[0], decimals=3))], frameon=False, loc=3)\n",
    "\n",
    "#plt.savefig('VAE_wgs_filt_nonb_per_species_nbnb.pdf', dpi=1000) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1adfc-04c7-4b8a-8825-548b54359537",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=sum_prev, y=specificity)\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel(\"Prevalence\")\n",
    "plt.ylabel(\"Specificity\")\n",
    "plt.plot([0.0, 1], [1, 0.0], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "plt.legend([\"Spearman r= -0.54\"], frameon=False, loc=3)\n",
    "\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.legend([\"Spearman r=\" + str(np.round(stats.spearmanr(sum_prev, specificity)[0], decimals=3))], frameon=False, loc=3)\n",
    "\n",
    "#plt.savefig('VAE_wgs_filt_nonb_per_species_prev_nbnb.pdf', dpi=1000) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cdff5-fdc8-4cf8-a13d-ca01c7e77875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevalence=np.sum(X_train, axis=0)/X_train.shape[0]\n",
    "plt.scatter(x=sum_prev, y=sensitivity)\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel(\"Prevalence\")\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "plt.legend([\"Spearman r= 0.73\"], frameon=False, loc=4)\n",
    "\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.legend([\"Spearman r=\" + str(np.round(stats.spearmanr(sum_prev, sensitivity)[0], decimals=3))], frameon=False, loc=3)\n",
    "\n",
    "#plt.savefig('VAE_wgs_filt_nonb_per_species_prev_sens_nbnb.pdf', dpi=1000) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced3e88-95cf-4469-9b43-b01f8e170e5c",
   "metadata": {},
   "source": [
    "### Grab taxonomic info for features (i.e. columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd9250-d063-401a-8e19-66505aabcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_df = pd.read_csv(\"data/wgs_train_health.noab_data_to_ml.taxonomy.txt\", sep=\"\\t\")\n",
    "taxonomy_df['prev']=sum_prev\n",
    "taxonomy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b8bbd-0547-4c5a-ba06-16da86a9296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_df['tp']=sum_tps\n",
    "taxonomy_df['tn']=sum_tns\n",
    "taxonomy_df['fp']=sum_fps\n",
    "taxonomy_df['fn']=sum_fns\n",
    "taxonomy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7887b-34dd-4b68-902c-84fbf0702b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_df=taxonomy_df.sort_values(by=['prev'], ascending=False)\n",
    "taxonomy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869817b-a743-4958-a5c3-fc995a9ea602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bars in stack manner\n",
    "plt.bar(taxonomy_df['scientific_name'], taxonomy_df['tp'], color='r')\n",
    "plt.bar(taxonomy_df['scientific_name'], taxonomy_df['tn'], bottom=taxonomy_df['tp'], color='b')\n",
    "plt.bar(taxonomy_df['scientific_name'], taxonomy_df['fp'], bottom=taxonomy_df['tp']+taxonomy_df['tn'], color='y')\n",
    "plt.bar(taxonomy_df['scientific_name'], taxonomy_df['fn'], bottom=taxonomy_df['tp']+taxonomy_df['tn']+taxonomy_df['fp'], color='g')\n",
    "plt.ylim([0,len(test_DS)*100])\n",
    "plt.xlabel(\"Species\")\n",
    "plt.xticks(fontsize=4, rotation = 90)\n",
    "plt.ylabel(\"total # of examples\")\n",
    "plt.legend([\"tp\", \"tn\", \"fp\", \"fn\"])\n",
    "plt.title(\"Accuracy metrics sorted by prevalence\")\n",
    "plt.savefig('graphs/VAE_wgs_species_acc_test.pdf', dpi=1000, bbox_inches='tight') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b09299-0b18-4c5d-a61d-4031a7893a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(taxonomy_df['scientific_name'], taxonomy_df['prev']*len(test_DS)*100, color='r')\n",
    "plt.xlabel(\"Species\")\n",
    "plt.ylim([0,len(test_DS)*100])\n",
    "plt.xticks(fontsize=4, rotation = 90)\n",
    "plt.ylabel(\"total # of examples\")\n",
    "plt.title(\"Species sorted by prevalence\") ### i.e. all positives\n",
    "plt.savefig('graphs/VAE_wgs_species_prev_test.pdf', dpi=1000, bbox_inches='tight') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f3448-364c-4e56-a77e-96e3a1e184a4",
   "metadata": {},
   "source": [
    "### This is how one can evaluate model on external validation data (i.e. rerun the above plots):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02eea5f-1215-4d10-ac07-499afbb9a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data in the same format as data_df (rows - samples, columns species in the same order)\n",
    "validation_df = pd.read_csv(\"data/wgs_test_health.ab_data_to_ml.txt\", sep=\"\\t\")\n",
    "#validation_df = pd.read_csv(\"data/wgs_test_disease_data_to_ml.txt\", sep=\"\\t\")\n",
    "\n",
    "print(validation_df)\n",
    "\n",
    "validation=validation_df.to_numpy()\n",
    "\n",
    "zero_thr = 1e-6\n",
    "validation_clr = np.log((validation+zero_thr) / gmean_train)\n",
    "validation_scaled = scaler.transform(validation_clr)\n",
    "\n",
    "X_validation_scaled = validation_scaled\n",
    "y_validation_scaled = validation_scaled\n",
    "\n",
    "X_validation_scaled=torch.from_numpy(X_validation_scaled).float()\n",
    "y_validation_scaled=torch.from_numpy(y_validation_scaled).float()\n",
    "\n",
    "#### dataset build \n",
    "Validation = CustomDataset(X_validation_scaled, y_validation_scaled)\n",
    "\n",
    "### create batch spits of data\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "validation_DS = DataLoader(Validation, batch_size=100, shuffle=True, drop_last=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd27ea-715f-4bcb-934d-811b2bce43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate true positive:\n",
    "tps=np.zeros((true_x.shape[1], len(validation_DS)))\n",
    "tns=np.zeros((true_x.shape[1], len(validation_DS)))\n",
    "fps=np.zeros((true_x.shape[1], len(validation_DS)))\n",
    "fns=np.zeros((true_x.shape[1], len(validation_DS)))\n",
    "prev=np.zeros((true_x.shape[1], len(validation_DS)))\n",
    "#i=np.zeros((true_x.shape[1], 2))\n",
    "accs=0\n",
    "zero_thr = -0.6\n",
    "for (idx, batch) in enumerate(validation_DS):\n",
    "    print(\"num\")\n",
    "    \n",
    "    true_x_bin = (batch['Features']>zero_thr).float()\n",
    "    \n",
    "    recon_x, u, logvar = model(batch['Features'])\n",
    "    recon_x_bin=(recon_x.detach()>zero_thr).float()\n",
    " \n",
    "    acc = (recon_x_bin == true_x_bin).float().mean()\n",
    "    acc = float(acc)\n",
    "    accs +=acc\n",
    "    \n",
    "    true_x_bin=true_x_bin.numpy()\n",
    "    recon_x_bin=recon_x_bin.numpy()\n",
    "    \n",
    "    print(recon_x_bin.shape)\n",
    "    prev[:,idx]=np.sum(true_x_bin, axis=0)\n",
    "    for i in range(true_x_bin.shape[1]):\n",
    "        tp=0\n",
    "        tn=0\n",
    "        fn=0\n",
    "        fp=0\n",
    "        #print(true_x_bin.shape[0])\n",
    "        for j in range(true_x_bin.shape[0]):\n",
    "            if(true_x_bin[j,i]==1):\n",
    "                if(recon_x_bin[j,i]==1):\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "            else:\n",
    "                if(recon_x_bin[j,i]==1):\n",
    "                    fp+=1\n",
    "                else:\n",
    "                    tn+=1\n",
    "        #print(i)\n",
    "        #print(idx)\n",
    "        tps[i, idx]=tp\n",
    "        tns[i, idx]=tn\n",
    "        fps[i, idx]=fp\n",
    "        fns[i, idx]=fn\n",
    "        #print(tp+fn)\n",
    "        #print(np.sum(true_x_bin[:,i]))\n",
    "    \n",
    "sum_tps=np.sum(tps, axis=1)\n",
    "sum_tns=np.sum(tns, axis=1)\n",
    "sum_fps=np.sum(fps, axis=1)\n",
    "sum_fns=np.sum(fns, axis=1)\n",
    "sum_prev=np.sum(prev, axis=1)/len(validation_DS)/100\n",
    "#print(sum_tps)\n",
    "#sum_tns=tns[:,0]+tns[:,1]\n",
    "#sum_fps=fps[:,0]+fps[:,1]\n",
    "#sum_fns=tps[:,0]+fns[:,1]\n",
    "\n",
    "sensitivity=sum_tps/(sum_tps+sum_fns)#+0.5)\n",
    "specificity=sum_tns/(sum_tns+sum_fps)#+0.5)   \n",
    "\n",
    "print(accs/len(validation_DS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752071dc-9f6b-4362-bc6c-7545361b1565",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Count true/false positive/negative _per sample_ statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af05d2-f194-4d1d-9796-01d2cc48d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check sample to sample variability\n",
    "\n",
    "# calculate true positive:\n",
    "tps=np.zeros((true_x.shape[0], len(test_DS)))\n",
    "tns=np.zeros((true_x.shape[0], len(test_DS)))\n",
    "fps=np.zeros((true_x.shape[0], len(test_DS)))\n",
    "fns=np.zeros((true_x.shape[0], len(test_DS)))\n",
    "#i=np.zeros((true_x.shape[1], 2))\n",
    "for (idx, batch) in enumerate(test_DS):\n",
    "    zero_thr = -0.6\n",
    "    true_x_bin = (batch['Features']>zero_thr).float().numpy()\n",
    "    \n",
    "    recon_x, u, logvar = model(batch['Features'])\n",
    "    recon_x_bin=(recon_x.detach()>zero_thr).float().numpy()\n",
    "\n",
    "    print(recon_x_bin.shape)\n",
    "    for i in range(true_x_bin.shape[0]):\n",
    "        tp=0\n",
    "        tn=0\n",
    "        fn=0\n",
    "        fp=0\n",
    "        #print(true_x_bin.shape[0])\n",
    "        for j in range(true_x_bin.shape[1]):\n",
    "            if(true_x_bin[i,j]==1):\n",
    "                if(recon_x_bin[i,j]==1):\n",
    "                    tp+=1\n",
    "                else:\n",
    "                    fn+=1\n",
    "            else:\n",
    "                if(recon_x_bin[i,j]==1):\n",
    "                    fp+=1\n",
    "                else:\n",
    "                    tn+=1\n",
    "        #print(i)\n",
    "        #print(idx)\n",
    "        tps[i, idx]=tp\n",
    "        tns[i, idx]=tn\n",
    "        fps[i, idx]=fp\n",
    "        fns[i, idx]=fn\n",
    "\n",
    "\n",
    "sum_tps=tps.flatten()\n",
    "sum_tns=tns.flatten()\n",
    "sum_fps=fps.flatten()\n",
    "sum_fns=fns.flatten()\n",
    "\n",
    "sensitivity=sum_tps/((sum_tps+sum_fns))#+0.5)\n",
    "specificity=sum_tns/((sum_tns+sum_fps))#+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854a462-5fea-4223-a891-26eb7e9edace",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=sensitivity, y=specificity, alpha=0.3)\n",
    "plt.ylim([0, 1.1])\n",
    "plt.xlim([0, 1.1])\n",
    "plt.xlabel(\"Sensitivity\")\n",
    "plt.ylabel(\"Specificity\")\n",
    "plt.legend([\"Spearman r= -0.98\"], frameon=False, loc=3)\n",
    "plt.plot([0.0, 1], [1, 0.0], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "\n",
    "plt.plot([0.2, 1], [1, 0.2], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "plt.plot([0.4, 1], [1, 0.4], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "plt.plot([0.6, 1], [1, 0.6], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "plt.plot([0.8, 1], [1, 0.8], ls=\"--\", linewidth=\".3\", c=\".3\")\n",
    "\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.legend([\"Spearman r=\" + str(np.round(stats.spearmanr(sensitivity, specificity)[0], decimals=3))], frameon=False, loc=3)\n",
    "\n",
    "#plt.savefig('graphs/VAE_wgs_filt_nonbin_per_samples_train_nbnb.pdf', dpi=1000) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97dc2d4-a9c9-42e6-9916-349b7f68ee04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
